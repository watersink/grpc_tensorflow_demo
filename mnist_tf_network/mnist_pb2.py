# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: mnist.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
from google.protobuf import descriptor_pb2
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2


DESCRIPTOR = _descriptor.FileDescriptor(
  name='mnist.proto',
  package='tensorflow.serving',
  syntax='proto3',
  serialized_pb=_b('\n\x0bmnist.proto\x12\x12tensorflow.serving\x1a&tensorflow/core/framework/tensor.proto\"\xa2\x01\n\x13MnistPredictRequest\x12\x43\n\x06inputs\x18\x01 \x03(\x0b\x32\x33.tensorflow.serving.MnistPredictRequest.InputsEntry\x1a\x46\n\x0bInputsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12&\n\x05value\x18\x02 \x01(\x0b\x32\x17.tensorflow.TensorProto:\x02\x38\x01\"\xa7\x01\n\x14MnistPredictResponse\x12\x46\n\x07outputs\x18\x01 \x03(\x0b\x32\x35.tensorflow.serving.MnistPredictResponse.OutputsEntry\x1aG\n\x0cOutputsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12&\n\x05value\x18\x02 \x01(\x0b\x32\x17.tensorflow.TensorProto:\x02\x38\x01\x32}\n\x16MnistPredictionService\x12\x63\n\x0cMnistPredict\x12\'.tensorflow.serving.MnistPredictRequest\x1a(.tensorflow.serving.MnistPredictResponse\"\x00\x42\x03\xf8\x01\x01\x62\x06proto3')
  ,
  dependencies=[tensorflow_dot_core_dot_framework_dot_tensor__pb2.DESCRIPTOR,])




_MNISTPREDICTREQUEST_INPUTSENTRY = _descriptor.Descriptor(
  name='InputsEntry',
  full_name='tensorflow.serving.MnistPredictRequest.InputsEntry',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='key', full_name='tensorflow.serving.MnistPredictRequest.InputsEntry.key', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='value', full_name='tensorflow.serving.MnistPredictRequest.InputsEntry.value', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001')),
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=168,
  serialized_end=238,
)

_MNISTPREDICTREQUEST = _descriptor.Descriptor(
  name='MnistPredictRequest',
  full_name='tensorflow.serving.MnistPredictRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='inputs', full_name='tensorflow.serving.MnistPredictRequest.inputs', index=0,
      number=1, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[_MNISTPREDICTREQUEST_INPUTSENTRY, ],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=76,
  serialized_end=238,
)


_MNISTPREDICTRESPONSE_OUTPUTSENTRY = _descriptor.Descriptor(
  name='OutputsEntry',
  full_name='tensorflow.serving.MnistPredictResponse.OutputsEntry',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='key', full_name='tensorflow.serving.MnistPredictResponse.OutputsEntry.key', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='value', full_name='tensorflow.serving.MnistPredictResponse.OutputsEntry.value', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001')),
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=337,
  serialized_end=408,
)

_MNISTPREDICTRESPONSE = _descriptor.Descriptor(
  name='MnistPredictResponse',
  full_name='tensorflow.serving.MnistPredictResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='outputs', full_name='tensorflow.serving.MnistPredictResponse.outputs', index=0,
      number=1, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[_MNISTPREDICTRESPONSE_OUTPUTSENTRY, ],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=241,
  serialized_end=408,
)

_MNISTPREDICTREQUEST_INPUTSENTRY.fields_by_name['value'].message_type = tensorflow_dot_core_dot_framework_dot_tensor__pb2._TENSORPROTO
_MNISTPREDICTREQUEST_INPUTSENTRY.containing_type = _MNISTPREDICTREQUEST
_MNISTPREDICTREQUEST.fields_by_name['inputs'].message_type = _MNISTPREDICTREQUEST_INPUTSENTRY
_MNISTPREDICTRESPONSE_OUTPUTSENTRY.fields_by_name['value'].message_type = tensorflow_dot_core_dot_framework_dot_tensor__pb2._TENSORPROTO
_MNISTPREDICTRESPONSE_OUTPUTSENTRY.containing_type = _MNISTPREDICTRESPONSE
_MNISTPREDICTRESPONSE.fields_by_name['outputs'].message_type = _MNISTPREDICTRESPONSE_OUTPUTSENTRY
DESCRIPTOR.message_types_by_name['MnistPredictRequest'] = _MNISTPREDICTREQUEST
DESCRIPTOR.message_types_by_name['MnistPredictResponse'] = _MNISTPREDICTRESPONSE
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

MnistPredictRequest = _reflection.GeneratedProtocolMessageType('MnistPredictRequest', (_message.Message,), dict(

  InputsEntry = _reflection.GeneratedProtocolMessageType('InputsEntry', (_message.Message,), dict(
    DESCRIPTOR = _MNISTPREDICTREQUEST_INPUTSENTRY,
    __module__ = 'mnist_pb2'
    # @@protoc_insertion_point(class_scope:tensorflow.serving.MnistPredictRequest.InputsEntry)
    ))
  ,
  DESCRIPTOR = _MNISTPREDICTREQUEST,
  __module__ = 'mnist_pb2'
  # @@protoc_insertion_point(class_scope:tensorflow.serving.MnistPredictRequest)
  ))
_sym_db.RegisterMessage(MnistPredictRequest)
_sym_db.RegisterMessage(MnistPredictRequest.InputsEntry)

MnistPredictResponse = _reflection.GeneratedProtocolMessageType('MnistPredictResponse', (_message.Message,), dict(

  OutputsEntry = _reflection.GeneratedProtocolMessageType('OutputsEntry', (_message.Message,), dict(
    DESCRIPTOR = _MNISTPREDICTRESPONSE_OUTPUTSENTRY,
    __module__ = 'mnist_pb2'
    # @@protoc_insertion_point(class_scope:tensorflow.serving.MnistPredictResponse.OutputsEntry)
    ))
  ,
  DESCRIPTOR = _MNISTPREDICTRESPONSE,
  __module__ = 'mnist_pb2'
  # @@protoc_insertion_point(class_scope:tensorflow.serving.MnistPredictResponse)
  ))
_sym_db.RegisterMessage(MnistPredictResponse)
_sym_db.RegisterMessage(MnistPredictResponse.OutputsEntry)


DESCRIPTOR.has_options = True
DESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b('\370\001\001'))
_MNISTPREDICTREQUEST_INPUTSENTRY.has_options = True
_MNISTPREDICTREQUEST_INPUTSENTRY._options = _descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001'))
_MNISTPREDICTRESPONSE_OUTPUTSENTRY.has_options = True
_MNISTPREDICTRESPONSE_OUTPUTSENTRY._options = _descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001'))

_MNISTPREDICTIONSERVICE = _descriptor.ServiceDescriptor(
  name='MnistPredictionService',
  full_name='tensorflow.serving.MnistPredictionService',
  file=DESCRIPTOR,
  index=0,
  options=None,
  serialized_start=410,
  serialized_end=535,
  methods=[
  _descriptor.MethodDescriptor(
    name='MnistPredict',
    full_name='tensorflow.serving.MnistPredictionService.MnistPredict',
    index=0,
    containing_service=None,
    input_type=_MNISTPREDICTREQUEST,
    output_type=_MNISTPREDICTRESPONSE,
    options=None,
  ),
])
_sym_db.RegisterServiceDescriptor(_MNISTPREDICTIONSERVICE)

DESCRIPTOR.services_by_name['MnistPredictionService'] = _MNISTPREDICTIONSERVICE

# @@protoc_insertion_point(module_scope)
